{
  "metadata": {
    "name": "LiveCommentsAnalysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type-update)\nCREATE TABLE yt_live_comments (\n    videoId STRING,\n    author STRING,\n    datetime TIMESTAMP(3),\n    message STRING,\n    WATERMARK FOR datetime AS datetime - INTERVAL \u00275\u0027 SECOND\n)\nPARTITIONED BY (videoId)\nWITH (\n    \u0027connector\u0027 \u003d \u0027kinesis\u0027,\n    \u0027stream\u0027 \u003d \u0027youtube_stream\u0027,\n    \u0027aws.region\u0027 \u003d \u0027us-east-1\u0027,\n    \u0027scan.stream.initpos\u0027 \u003d \u0027LATEST\u0027,\n    \u0027format\u0027 \u003d \u0027json\u0027,\n    \u0027json.timestamp-format.standard\u0027 \u003d \u0027ISO-8601\u0027\n)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type-update)\nselect * from yt_live_comments"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type-update)\nSELECT videoId, COUNT(*) AS comment_count FROM yt_live_comments GROUP BY videoId;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink\nimport org.apache.flink.table.functions.ScalarFunction\nimport java.time.LocalDateTime\nimport java.time.ZoneOffset\n\nclass DateTimeToEpoch extends ScalarFunction {\n  def eval(datetime: LocalDateTime) \u003d datetime.toEpochSecond(ZoneOffset.UTC)\n}\n\nbtenv.registerFunction(\"dt_transformation\", new DateTimeToEpoch())"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type-update)\nSELECT  message, dt_transformation(datetime) as epoch_time from yt_live_comments;"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\n"
    }
  ]
}